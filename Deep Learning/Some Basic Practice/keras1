#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Feb 10 15:05:23 2017

@author: wangbeanz
"""
# theano as backend
# regression
import numpy as np
np.random.randn(2)  # for reproducibility
from keras.models import Sequential  # add NN sequentially
from keras.layers import Dense
import matplotlib.pyplot as plt

# create some data
# return evenly spaced numbers over a specified interval.
X = np.linspace(-1, 1, 200)
np.random.shuffle(X)  # randomize the data
Y = 0.5 * X + 2 + np.random.normal(0, 0.05, (200,))

# plot data
plt.scatter(X, Y)
plt.show()

X_train, Y_train = X[:160], Y[:160]
X_test, Y_test = X[160:], Y[160:]


# build a NN from the 1st layer to the last layer.
model = Sequential()
model.add(Dense(output_dim=1, input_dim=1))  # add a new NN
# model.add(Dense(output_dim=1))  # the input_dim is the last output_dim

           
# choose loss function nad optimizing method
model.compile(loss='mse', optimizer='sgd')  # stochastic gradient descent.


# training
print('\ntraining: ')
for step in range(501):
    cost = model.train_on_batch(X_train, Y_train)
    if step % 100 == 0:
        print('train cost: ', cost)


# testing
print('\ntesting: ')
cost = model.evaluate(X_test, Y_test, batch_size=40)
print('test cost: ', cost)
W, b = model.layers[0].get_weights()  # get the weights and bias of the first layer.
print('\nWeights: ', W, '\nbias: ', b)

# plotting the predictions
Y_pred = model.predict(X_test)
plt.scatter(X_test, Y_test)
plt.plot(X_test, Y_pred)
plt.show()








